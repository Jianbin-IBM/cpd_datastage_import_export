{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43eb3b1d-e6e6-4ef8-a646-361d1ffc93ad",
   "metadata": {},
   "source": [
    "# Demo Code: Export&Import Selected Assets to a zip file\n",
    "\n",
    "Actually, every selected assets have dedicated command. Highly recommended to use dedicated one unless you really want to put them togehter.\n",
    "\n",
    "## Prerequisite\n",
    "1. Create your own yaml based on [configuration_template.yaml](./configuration_template.yaml), and modify \"CONFIG_FILE\" below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564b6e2a-bd78-404d-9324-06353e7c710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2d50d3-40b6-4e5d-a753-e217157d83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to a local file with credentials. It is not synced to git.\n",
    "CONFIG_FILE = \"export_import_selected_assets.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331bf555-4e19-4598-9622-677b41c57e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPORT_PRJ_NAME= Multicloud Data Integration L3 Tech Lab\n",
      "IMPORT_PRJ_NAME= DataStage Import\n"
     ]
    }
   ],
   "source": [
    "# Load parameters from the YAML file\n",
    "with open(CONFIG_FILE, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "DSJOB_URL = config['url']\n",
    "DSJOB_USER = config['user']\n",
    "DSJOB_PWD = config['password']\n",
    "EXPORT_PRJ_NAME = config['export_prj_name']\n",
    "if 'export_zip_name' in config:\n",
    "    EXPORT_ZIP_NAME = config['export_zip_name']\n",
    "else:\n",
    "    EXPORT_ZIP_NAME = EXPORT_PRJ_NAME+\"_assets.zip\"\n",
    "    \n",
    "datastages =   config['datastages']\n",
    "pipelines =  config['pipelines']\n",
    "testcases = config['testcases']\n",
    "\n",
    "IMPORT_PRJ_NAME = config['import_prj_name']\n",
    "print(\"EXPORT_PRJ_NAME=\",EXPORT_PRJ_NAME)\n",
    "print(\"IMPORT_PRJ_NAME=\",IMPORT_PRJ_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe1d7e0-f964-41ed-9fc7-7229d48d6900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CPDCTL_ENABLE_DSJOB=true\n",
      "env: CPDCTL_ENABLE_DATASTAGE=true\n",
      "env: CPDCTL_ENABLE_VOLUMES=1\n",
      "true\n",
      "true\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Enable dsjob\n",
    "%env CPDCTL_ENABLE_DSJOB=true\n",
    "%env CPDCTL_ENABLE_DATASTAGE=true\n",
    "%env CPDCTL_ENABLE_VOLUMES=1\n",
    "!echo $CPDCTL_ENABLE_DSJOB\n",
    "!echo $CPDCTL_ENABLE_DATASTAGE\n",
    "!echo $CPDCTL_ENABLE_VOLUMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b61bdb-cf27-45d4-a903-7f0a1c3f75e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to profile \"CP4D-profile\".\n"
     ]
    }
   ],
   "source": [
    "# Configure cpdctl with the parameters\n",
    "!cpdctl config user set CP4D-user --username \"$DSJOB_USER\" --password \"$DSJOB_PWD\"\n",
    "!cpdctl config profile set CP4D-profile --url \"$DSJOB_URL\" --user CP4D-user\n",
    "!cpdctl config profile use CP4D-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac063ba4-a1c0-476b-85bf-b614566846d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Business Catalog Enrichment\n",
      "DataStage Import1\n",
      "GDPR Lineage\n",
      "test_python_pipeline\n",
      "DataStage Import\n",
      "DQ Definition_Rules\n",
      "Multicloud Data Integration L3 Tech Lab\n",
      "Data Replication Lab\n",
      "Auto Policy Risk\n",
      "evaluate-an-ml-model\n",
      "Data-Science-and-MLOps\n",
      "\n",
      "Total: 11 Projects\n",
      "\n",
      "Status code = 0\n"
     ]
    }
   ],
   "source": [
    "# list all projects\n",
    "!cpdctl dsjob list-projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6948dd9b-4588-473b-831d-05a5b8a7c390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpdctl dsjob export-zip --project \"Multicloud Data Integration L3 Tech Lab\" --name \"Employee Ranking\" --pipeline \"Pipeline1\" --pipeline \"Pipeline2\"  --file-name \"own_name.zip\"\n"
     ]
    }
   ],
   "source": [
    "# Format the string for the export-zip\n",
    "datastages_str=''\n",
    "pipelines_str=''\n",
    "testcases_str=''\n",
    "if len(datastages)>0:\n",
    "    datastages_str = ' '.join(f'--name \"{datastage}\"' for datastage in datastages)\n",
    "if len(pipelines)>0:\n",
    "    pipelines_str = ' '.join(f'--pipeline \"{pipeline}\"' for pipeline in pipelines)\n",
    "if len(testcases)>0:\n",
    "    testcases_str = ' '.join(f'--name \"{testcases}\"' for testcase in testcases)\n",
    "\n",
    "cmd_str = f'cpdctl dsjob export-zip --project \"{EXPORT_PRJ_NAME}\" \\\n",
    "{datastages_str} {pipelines_str} {testcases_str} --file-name \"{EXPORT_ZIP_NAME}\"'\n",
    "\n",
    "print(cmd_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca8fd2ab-83b7-4f11-9cb3-d18cb5ebd0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\n",
      "Status code =  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(cmd_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290a4b7-ddec-41ad-b854-9ba17c5f46ab",
   "metadata": {},
   "source": [
    "## Import to a project with **import-zip**\n",
    "\n",
    "Connection between development and production environment are usually different. Hence we usually skip \"connection\" with \"--skip-on-replace connection\" flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c04337-7492-4c2a-b0d0-e8a6cd34d76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "2024-06-03 21:32:16: Waiting until import finishes, import id: 2e14fc12-e8aa-42bf-bede-e07eaebe2000\n",
      "2024-06-03 21:32:26: Project import status: started,  total: 5, completed: 3, failed: 0, skipped: 2.\n",
      "2024-06-03 21:32:46: Project import status: completed,  total: 5, completed: 3, failed: 0, skipped: 2.\n",
      "Information:\n",
      "\tConnection: Data Virtualization,\t  New connection is exactly the same as an existing connection, resource is not updated.\n",
      "\n",
      "\tConnection: Data Warehouse,\t  New connection is exactly the same as an existing connection, resource is not updated.\n",
      "\n",
      "\n",
      "Status code =  0\n"
     ]
    }
   ],
   "source": [
    "!cpdctl dsjob import-zip --project \"$IMPORT_PRJ_NAME\" --file-name \"$EXPORT_ZIP_NAME\" --conflict-resolution replace --skip-on-replace connection --wait 200 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
